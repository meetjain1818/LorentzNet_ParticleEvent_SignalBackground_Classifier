{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d924c0ee-7ac2-49e8-8157-0b3b015a626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import traceback\n",
    "from pprint import pprint\n",
    "\n",
    "# --- Constants ---\n",
    "# For original GNN node features\n",
    "ORIGINAL_GNN_NODE_FEATURES = ['Eta', 'Phi', 'pT', 'E'] # What you used for 'nodes' previously\n",
    "\n",
    "# For LorentzNet 4-vectors\n",
    "FOUR_VECTOR_COLS_FROM_DF = ['E', 'Px', 'Py', 'Pz']\n",
    "\n",
    "# For LorentzNet scalar features\n",
    "LORENTZNET_SCALAR_FEATURE_ORDER = ['particle_type', 'btag_status', 'invariant_mass']\n",
    "# particle_type: 0 for photon, 1 for jet\n",
    "\n",
    "# Max particles from input DataFrame\n",
    "MAX_JETS_INPUT = 15\n",
    "MAX_PHOTONS_INPUT = 3\n",
    "\n",
    "# Original DataFrame feature names used in filtering\n",
    "JET_DF_FEATURES = ['Eta', 'Phi', 'pT', 'Px', 'Py', 'Pz', 'E'] # For filter_jets_by_eta\n",
    "\n",
    "# --- Utility Functions (load_data, save_to_json - assume they are defined) ---\n",
    "# ... (Your existing load_data and save_to_json) ...\n",
    "def load_data(filepath: str, sep: str = '\\t') -> pd.DataFrame | None:\n",
    "    try:\n",
    "        print(f\"Loading data from {filepath}...\")\n",
    "        df = pd.read_csv(filepath, sep=sep, low_memory=False)\n",
    "        print(f\"--- Data loaded successfully: {df.shape[0]} events, {df.shape[1]} columns :)\")\n",
    "        return df\n",
    "    except FileNotFoundError: return None\n",
    "    except pd.errors.EmptyDataError: return None\n",
    "    except Exception: traceback.print_exc(); return None\n",
    "\n",
    "def save_to_json(data: list[dict], filepath: str) -> bool:\n",
    "    if not isinstance(data, list): return False\n",
    "    if not data: return False\n",
    "    print(f\"Attempting to save {len(data)} events to JSON file: {filepath}\")\n",
    "    try:\n",
    "        with open(filepath, 'w') as f:\n",
    "            def nan_to_null(obj):\n",
    "                if isinstance(obj, float) and np.isnan(obj): return None\n",
    "                if isinstance(obj, (np.float32, np.float64)): return float(obj) # Convert numpy floats\n",
    "                if isinstance(obj, (np.int32, np.int64)): return int(obj) # Convert numpy ints\n",
    "                return obj\n",
    "            json.dump(data, f, indent=2, default=nan_to_null)\n",
    "        print(\"JSON file saved successfully.\"); return True\n",
    "    except Exception: traceback.print_exc(); return False\n",
    "\n",
    "# --- Filtering Functions (filter_zero_multiplicity, filter_jets_by_eta, filter_empty_events) ---\n",
    "# ... (Your existing filtering functions) ...\n",
    "def filter_zero_multiplicity(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes events with zero jetmultiplicity.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with event data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with zero jetmultiplicity events removed.\n",
    "                     Returns None if the input DataFrame is invalid or lacks\n",
    "                     the 'jetmultiplicity' column.\n",
    "    \"\"\"\n",
    "    if df is None or not isinstance(df, pd.DataFrame):\n",
    "        print(\"*** Error: Invalid input DataFrame :(\")\n",
    "        return None\n",
    "    if 'jetmultiplicity' not in df.columns:\n",
    "        print(\"*** Error: 'jetmultiplicity' column not found in DataFrame :(\")\n",
    "        print(\"*** Returning the Original Dataframe...\")\n",
    "        return df\n",
    "\n",
    "    initial_events = len(df)\n",
    "    print(f\"Initial number of events: {initial_events}\")\n",
    "\n",
    "    # Filter events where jetmultiplicity is greater than 0\n",
    "    df_filtered = df[df['jetmultiplicity'] > 0].copy()\n",
    "\n",
    "    removed_events = initial_events - len(df_filtered)\n",
    "    print(f\"--- Removed {removed_events} events with zero jetmultiplicity :)\")\n",
    "    print(f\"Number of events after filtering: {len(df_filtered)}\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def filter_jets_by_eta(df:pd.DataFrame, eta_min:float=-2.5, eta_max:float=2.5, max_jets:int=13) -> [pd.DataFrame, list]:\n",
    "    \"\"\"\n",
    "    Sets jet quantities to NaN if the jet's Eta is outside the specified range.\n",
    "\n",
    "    It iterates through each possible jet (1 to max_jets) and checks its Eta value.\n",
    "    If Eta is outside [eta_min, eta_max], all features (Eta, Phi, pT, Px, Py, Pz, E)\n",
    "    for that specific jet in that event are set to NaN.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with event data.\n",
    "        eta_min (float): The minimum allowed Eta value. Defaults to -2.5.\n",
    "        eta_max (float): The maximum allowed Eta value. Defaults to 2.5.\n",
    "        max_jets (int): The maximum number of jets to check per event. Defaults to 13.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with jet quantities potentially modified to NaN.\n",
    "                      Returns None if the input DataFrame is invalid.\n",
    "    \"\"\"\n",
    "    if df is None or not isinstance(df, pd.DataFrame):\n",
    "        print(\"*** Error: Invalid input DataFrame for Eta filtering :(\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Applying Eta filter: Keeping jets with Eta between {eta_min} and {eta_max}.\")\n",
    "    JET_FEATURES = ['Eta', 'Phi', 'pT', 'Px', 'Py', 'Pz', 'E']\n",
    "    df_modified = df.copy()\n",
    "    jet_eta_cols_in_df = []\n",
    "    for i in range(1, max_jets + 1):\n",
    "        eta_col = f'jet{i}_Eta'\n",
    "        if eta_col in df_modified.columns:\n",
    "            jet_eta_cols_in_df.append(eta_col)\n",
    "            mask = ~df_modified[eta_col].between(eta_min, eta_max, inclusive='both')\n",
    "            jet_cols = [f'jet{i}_{feature}' for feature in JET_FEATURES]\n",
    "            existing_jet_cols = [col for col in jet_cols if col in df_modified.columns]\n",
    "            if not existing_jet_cols:\n",
    "                continue\n",
    "            df_modified.loc[mask, existing_jet_cols] = np.nan\n",
    "    print(\"--- Eta filtering complete :)\")\n",
    "\n",
    "    return df_modified, jet_eta_cols_in_df\n",
    "\n",
    "\n",
    "def filter_empty_events(df:pd.DataFrame, jet_eta_cols:list, max_photons:int=3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes events that have no valid jets AND no valid photons after processing.\n",
    "\n",
    "    - No valid jets means all existing jet_Eta columns for the event are NaN.\n",
    "    - No valid photons means all existing isophoton_E columns are <= 0 (or NaN).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame after jet Eta filtering.\n",
    "        jet_eta_cols (list): List of jet_Eta column names that actually exist in df.\n",
    "        max_photons (int): Maximum number of photons to check.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with empty events removed, or None if input is invalid.\n",
    "    \"\"\"\n",
    "    if df is None or not isinstance(df, pd.DataFrame):\n",
    "        print(\"*** Error: Invalid input DataFrame for empty event filtering :(\")\n",
    "        return None\n",
    "    if not jet_eta_cols:\n",
    "         print(\"*** Warning: No jet Eta columns found in DataFrame. Cannot filter based on jets :(\")\n",
    "         has_no_valid_jets = pd.Series([True] * len(df), index=df.index) # Assume no jets if no columns\n",
    "    else:\n",
    "        # Check rows where ALL existing jet_Eta columns are NaN\n",
    "        has_no_valid_jets = df[jet_eta_cols].isnull().all(axis=1)\n",
    "\n",
    "    photon_e_cols = [f'isophoton{i}_E' for i in range(1, max_photons + 1)]\n",
    "    photon_e_cols_in_df = [col for col in photon_e_cols if col in df.columns]\n",
    "\n",
    "    if not photon_e_cols_in_df:\n",
    "        print(\"*** Warning: No photon Energy columns found in DataFrame. Cannot filter based on photons :(\")\n",
    "        has_no_valid_photons = pd.Series([True] * len(df), index=df.index) # Assume no photons if no columns\n",
    "    else:\n",
    "        has_no_valid_photons = (df[photon_e_cols_in_df].fillna(0) <= 0).all(axis=1)\n",
    "\n",
    "    # Identify events to remove (those having no valid jets AND no valid photons)\n",
    "    is_empty_event = has_no_valid_jets & has_no_valid_photons\n",
    "\n",
    "    # Filter the DataFrame: keep rows where is_empty_event is False\n",
    "    df_filtered = df[~is_empty_event].copy()\n",
    "\n",
    "    removed_count = len(df) - len(df_filtered)\n",
    "    if removed_count > 0:\n",
    "        print(f\"Removed {removed_count} events with no valid jets AND no valid photons :)\")\n",
    "    else:\n",
    "        print(\"No events found with both empty jets and empty photons.\")\n",
    "    print(f\"Number of events after empty event filtering: {len(df_filtered)}\")\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "# --- Calculation Helper Functions ---\n",
    "def calculate_delta_r_robust(eta1: float | None, phi1: float | None,\n",
    "                             eta2: float | None, phi2: float | None) -> float:\n",
    "    # ... (Your existing calculate_delta_r_robust function) ...\n",
    "    if any(v is None for v in [eta1, phi1, eta2, phi2]): return np.nan\n",
    "    try:\n",
    "        eta1_f, phi1_f, eta2_f, phi2_f = map(float, [eta1, phi1, eta2, phi2])\n",
    "        deta = eta1_f - eta2_f; dphi = phi1_f - phi2_f\n",
    "        dphi = np.arctan2(np.sin(dphi), np.cos(dphi)) # Normalize phi to [-pi, pi]\n",
    "        delta_r_sq = deta**2 + dphi**2\n",
    "        if isinstance(delta_r_sq, complex) or delta_r_sq < 0: return np.nan\n",
    "        result = np.sqrt(delta_r_sq)\n",
    "        return result if not np.isnan(result) else np.nan\n",
    "    except (TypeError, ValueError): return np.nan\n",
    "\n",
    "\n",
    "def calculate_invariant_mass_robust(four_vectors_list_of_dicts: list[dict]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates invariant mass from a list of particle dictionaries,\n",
    "    each expected to have 'E', 'Px', 'Py', 'Pz' keys.\n",
    "    \"\"\"\n",
    "    if not four_vectors_list_of_dicts: return np.nan\n",
    "    four_vectors_for_calc = []\n",
    "    for p_dict in four_vectors_list_of_dicts:\n",
    "        try:\n",
    "            fv = [float(p_dict['E']), float(p_dict['Px']), float(p_dict['Py']), float(p_dict['Pz'])]\n",
    "            if any(np.isnan(v) for v in fv): return np.nan # Skip if any component is NaN\n",
    "            four_vectors_for_calc.append(fv)\n",
    "        except (KeyError, TypeError, ValueError): return np.nan # Skip if keys missing or non-numeric\n",
    "    if not four_vectors_for_calc: return np.nan # No valid four-vectors extracted\n",
    "\n",
    "    # Now call the original mass calculation with the list of numeric lists\n",
    "    return _calculate_invariant_mass_from_list_of_lists(four_vectors_for_calc)\n",
    "\n",
    "def _calculate_invariant_mass_from_list_of_lists(four_vectors: list[list[float]]) -> float:\n",
    "    \"\"\"Helper: Calculates invariant mass from a list of [E, Px, Py, Pz] lists.\"\"\"\n",
    "    if not four_vectors: return np.nan\n",
    "    try:\n",
    "        fv_array = np.array(four_vectors, dtype=float)\n",
    "        if fv_array.ndim != 2 or fv_array.shape[1] != 4 or np.isnan(fv_array).any(): return np.nan\n",
    "        sum_fv = np.sum(fv_array, axis=0)\n",
    "        tot_E, tot_Px, tot_Py, tot_Pz = sum_fv\n",
    "        if np.isnan(sum_fv).any(): return np.nan\n",
    "        mass_squared = tot_E**2 - (tot_Px**2 + tot_Py**2 + tot_Pz**2)\n",
    "        if np.isnan(mass_squared) or mass_squared < -1e-9: return np.nan\n",
    "        if mass_squared < 0: mass_squared = 0.0\n",
    "        result = np.sqrt(mass_squared)\n",
    "        return result if not np.isnan(result) else np.nan\n",
    "    except (TypeError, ValueError, IndexError): return np.nan\n",
    "\n",
    "\n",
    "# --- Core Event Processing Function (Modified) ---\n",
    "def process_event_combined(event_series: pd.Series, event_label: int,\n",
    "                           max_jets_input: int, max_photons_input: int) -> dict | None:\n",
    "    \"\"\"\n",
    "    Processes a single event for both original GNN features and LorentzNet features.\n",
    "    \"\"\"\n",
    "    event_no = event_series.get('eventno')\n",
    "    if event_no is None: return None\n",
    "    try: event_no = int(event_no)\n",
    "    except (ValueError, TypeError): return None\n",
    "\n",
    "    # For original GNN structure\n",
    "    original_gnn_nodes = [] # List of [Eta, Phi, pT, E]\n",
    "    node_positions_for_edges = [] # List of [Eta, Phi] for DeltaR\n",
    "    original_node_labels = [] # 0 for photon, 1 for jet\n",
    "    original_jet_btag_labels = [] # btag for jets, NaN for photons (aligned with original_gnn_nodes)\n",
    "\n",
    "    # For LorentzNet structure\n",
    "    lorentz_x_coords = []  # List of 4-vectors [E, Px, Py, Pz]\n",
    "    lorentz_h_scalars = [] # List of scalar feature vectors\n",
    "\n",
    "    # To collect particle dicts for invariant mass calculations\n",
    "    valid_particles_for_mass_calc = [] # List of dicts {'E': E, 'Px': Px, ... 'pT': pT, 'btag': btag_val }\n",
    "\n",
    "    # --- Extract Photons ---\n",
    "    for i in range(1, max_photons_input + 1):\n",
    "        p_prefix = f'isophoton{i}_'\n",
    "        pt_col = f'{p_prefix}pT'\n",
    "        if pt_col not in event_series.index or pd.isna(event_series[pt_col]) or event_series[pt_col] <= 0:\n",
    "            continue\n",
    "\n",
    "        # Extract all needed features, handling potential NaNs\n",
    "        try:\n",
    "            eta = float(event_series.get(f'{p_prefix}Eta', np.nan))\n",
    "            phi = float(event_series.get(f'{p_prefix}Phi', np.nan))\n",
    "            pt = float(event_series.get(f'{p_prefix}pT', np.nan)) # Should be >0 from check\n",
    "            e_kin = float(event_series.get(f'{p_prefix}E', np.nan))\n",
    "            px = float(event_series.get(f'{p_prefix}Px', np.nan))\n",
    "            py = float(event_series.get(f'{p_prefix}Py', np.nan))\n",
    "            pz = float(event_series.get(f'{p_prefix}Pz', np.nan))\n",
    "\n",
    "            # Check if essential features for node/4-vector are present\n",
    "            if any(np.isnan([eta, phi, pt, e_kin, px, py, pz])): continue\n",
    "\n",
    "            # Original GNN Node\n",
    "            original_gnn_nodes.append([eta, phi, pt, e_kin])\n",
    "            node_positions_for_edges.append([eta, phi])\n",
    "            original_node_labels.append(0) # Photon\n",
    "            original_jet_btag_labels.append(np.nan) # No btag for photon\n",
    "\n",
    "            # LorentzNet Features\n",
    "            lorentz_x_coords.append([e_kin, px, py, pz])\n",
    "            photon_mass = _calculate_invariant_mass_from_list_of_lists([[e_kin, px, py, pz]])\n",
    "            current_h_scalars = {'particle_type': 0.0, 'btag_status': 0.0, 'invariant_mass': photon_mass}\n",
    "            lorentz_h_scalars.append([current_h_scalars.get(k, np.nan) for k in LORENTZNET_SCALAR_FEATURE_ORDER])\n",
    "\n",
    "            valid_particles_for_mass_calc.append({'E':e_kin, 'Px':px, 'Py':py, 'Pz':pz, 'pT':pt, 'type':'photon'})\n",
    "\n",
    "        except (TypeError, ValueError): continue\n",
    "\n",
    "    # --- Extract Jets ---\n",
    "    for i in range(1, max_jets_input + 1):\n",
    "        j_prefix = f'jet{i}_'\n",
    "        pt_col = f'{j_prefix}pT'\n",
    "        if pt_col not in event_series.index or pd.isna(event_series[pt_col]) or event_series[pt_col] <= 0:\n",
    "            continue\n",
    "        try:\n",
    "            eta = float(event_series.get(f'{j_prefix}Eta', np.nan))\n",
    "            phi = float(event_series.get(f'{j_prefix}Phi', np.nan))\n",
    "            pt = float(event_series.get(f'{j_prefix}pT', np.nan))\n",
    "            e_kin = float(event_series.get(f'{j_prefix}E', np.nan))\n",
    "            px = float(event_series.get(f'{j_prefix}Px', np.nan))\n",
    "            py = float(event_series.get(f'{j_prefix}Py', np.nan))\n",
    "            pz = float(event_series.get(f'{j_prefix}Pz', np.nan))\n",
    "            btag_val_raw = event_series.get(f'{j_prefix}btag', np.nan)\n",
    "            btag_val = float(btag_val_raw) if not pd.isna(btag_val_raw) else 0.0 # Default non-btag to 0\n",
    "\n",
    "            if any(np.isnan([eta, phi, pt, e_kin, px, py, pz, btag_val])): continue\n",
    "\n",
    "            # Original GNN Node\n",
    "            original_gnn_nodes.append([eta, phi, pt, e_kin])\n",
    "            node_positions_for_edges.append([eta, phi])\n",
    "            original_node_labels.append(1) # Jet\n",
    "            original_jet_btag_labels.append(btag_val)\n",
    "\n",
    "            # LorentzNet Features\n",
    "            lorentz_x_coords.append([e_kin, px, py, pz])\n",
    "            jet_mass = _calculate_invariant_mass_from_list_of_lists([[e_kin, px, py, pz]])\n",
    "            current_h_scalars = {'particle_type': 1.0, 'btag_status': btag_val, 'invariant_mass': jet_mass}\n",
    "            lorentz_h_scalars.append([current_h_scalars.get(k, np.nan) for k in LORENTZNET_SCALAR_FEATURE_ORDER])\n",
    "\n",
    "            valid_particles_for_mass_calc.append({'E':e_kin, 'Px':px, 'Py':py, 'Pz':pz, 'pT':pt, 'type':'jet', 'btag':btag_val})\n",
    "        except (TypeError, ValueError): continue\n",
    "\n",
    "\n",
    "    num_total_nodes = len(original_gnn_nodes)\n",
    "    if num_total_nodes == 0: return None # No valid particles at all\n",
    "\n",
    "    # --- Original GNN Edges ---\n",
    "    edge_index_sources, edge_index_targets, edges_delta_r = [], [], []\n",
    "    if num_total_nodes >= 2:\n",
    "        for i in range(num_total_nodes):\n",
    "            for j in range(i + 1, num_total_nodes):\n",
    "                eta1, phi1 = node_positions_for_edges[i]\n",
    "                eta2, phi2 = node_positions_for_edges[j]\n",
    "                delta_r = calculate_delta_r_robust(eta1, phi1, eta2, phi2)\n",
    "                if not np.isnan(delta_r):\n",
    "                    edge_index_sources.extend([i, j]); edge_index_targets.extend([j, i])\n",
    "                    edges_delta_r.extend([delta_r, delta_r])\n",
    "    original_edge_index = [edge_index_sources, edge_index_targets]\n",
    "\n",
    "    # --- Original GNN Graph-Level Features ---\n",
    "    inv_mass_2leadingbj = np.nan\n",
    "    inv_mass_2leadingbj1p = np.nan\n",
    "    leading_isophoton_pt = np.nan\n",
    "\n",
    "    photons_from_valid = [p for p in valid_particles_for_mass_calc if p['type'] == 'photon']\n",
    "    jets_from_valid = [p for p in valid_particles_for_mass_calc if p['type'] == 'jet']\n",
    "\n",
    "    if photons_from_valid:\n",
    "        photons_sorted = sorted(photons_from_valid, key=lambda p: p['pT'], reverse=True)\n",
    "        leading_photon_dict = photons_sorted[0]\n",
    "        leading_isophoton_pt = leading_photon_dict['pT']\n",
    "    else:\n",
    "        leading_photon_dict = None\n",
    "\n",
    "    if len(jets_from_valid) >= 2:\n",
    "        # Sort by b-tag (desc) then pT (desc) to get leading b-jets preferentially\n",
    "        jets_sorted = sorted(jets_from_valid, key=lambda j: (j.get('btag', -np.inf), j.get('pT', -np.inf)), reverse=True)\n",
    "        leading_2_jets_dicts = jets_sorted[:2]\n",
    "        inv_mass_2leadingbj = calculate_invariant_mass_robust(leading_2_jets_dicts)\n",
    "        if leading_photon_dict:\n",
    "            inv_mass_2leadingbj1p = calculate_invariant_mass_robust(leading_2_jets_dicts + [leading_photon_dict])\n",
    "\n",
    "    # --- NaN to None for JSON and final counts ---\n",
    "    final_original_jet_btag = [b if not np.isnan(b) else None for b in original_jet_btag_labels]\n",
    "    final_lorentz_h_scalars = [[0.0 if np.isnan(s) else s for s in h_vec] for h_vec in lorentz_h_scalars]\n",
    "\n",
    "    num_final_nodes = len(original_gnn_nodes)\n",
    "    num_final_btag_jets = sum(1 for b in final_original_jet_btag if b == 1.0) # Count btags=1.0\n",
    "    num_final_isophotons = original_node_labels.count(0) # Count photons\n",
    "\n",
    "    combined_dict = {\n",
    "        'eventno': event_no,\n",
    "        'event_label': event_label,\n",
    "        'nodes': original_gnn_nodes,\n",
    "        'edges': [e if not np.isnan(e) else None for e in edges_delta_r],\n",
    "        'edge_index': original_edge_index,\n",
    "        'node_labels': original_node_labels,\n",
    "        'jet_btag_label': final_original_jet_btag, # This was your list of btags aligned with 'nodes'\n",
    "        'num_nodes': num_final_nodes,\n",
    "        'num_btag_jets': num_final_btag_jets,\n",
    "        'num_isophotons': num_final_isophotons,\n",
    "        'invMass_2leadingbj1p': float(inv_mass_2leadingbj1p) if not np.isnan(inv_mass_2leadingbj1p) else None,\n",
    "        'invMass_2leadingbj': float(inv_mass_2leadingbj) if not np.isnan(inv_mass_2leadingbj) else None,\n",
    "        'leading_isophoton_pT': float(leading_isophoton_pt) if not np.isnan(leading_isophoton_pt) else None,\n",
    "        # LorentzNet specific features\n",
    "        'x_coords': lorentz_x_coords,\n",
    "        'h_scalars': final_lorentz_h_scalars\n",
    "    }\n",
    "    return combined_dict\n",
    "\n",
    "\n",
    "# --- Main Pipeline Function (Modified to use the combined processor) ---\n",
    "def main_combined_pipeline(input_filepath: str, output_filepath: str,\n",
    "                           max_jets_input_df: int, max_photons_input_df: int,\n",
    "                           eta_min_filter: float, eta_max_filter: float,\n",
    "                           sep: str = '\\t') -> None:\n",
    "    \"\"\"\n",
    "    Runs the full data pipeline: load, filter, process for combined GNN/LorentzNet, save.\n",
    "    \"\"\"\n",
    "       # 1. Load Data\n",
    "    raw_df = load_data(input_filepath, sep=sep)\n",
    "    if raw_df is not None:\n",
    "        df_filtered_multiplicity = raw_df\n",
    "\n",
    "        if df_filtered_multiplicity is not None:\n",
    "            # 3. Filter jets based on Eta range (Sets invalid jets to NaN)\n",
    "            df_eta_filtered, existing_jet_eta_cols = filter_jets_by_eta(df_filtered_multiplicity,\n",
    "                                                                        eta_min=eta_min_filter,\n",
    "                                                                        eta_max=eta_max_filter,\n",
    "                                                                        max_jets=max_jets_input_df)\n",
    "            print(existing_jet_eta_cols)\n",
    "\n",
    "            if df_eta_filtered is not None and not df_eta_filtered.empty:\n",
    "                # 4. Filter out events with no valid jets AND no valid photons\n",
    "                df_final_filtered = filter_empty_events(df_eta_filtered,\n",
    "                                         jet_eta_cols=existing_jet_eta_cols,\n",
    "                                         max_photons=max_photons_input_df)\n",
    "\n",
    "            elif df_eta_filtered is not None and df_eta_filtered.empty:\n",
    "                 print(\"*** All events were removed during the Eta filtering step :(\")\n",
    "            else:\n",
    "                print(\"*** Eta filtering step failed :(\")\n",
    "        elif df_filtered_multiplicity is not None and df_filtered_multiplicity.empty:\n",
    "            print(\"*** All events were removed during the jet multiplicity filtering step :(\")\n",
    "        else:\n",
    "            print(\"*** Jet multiplicity filtering step failed :(\")\n",
    "    else:\n",
    "        print(\"*** Data loading failed. Aborting processing :(\")\n",
    "    # 3. Determine Event Label (same as before)\n",
    "    event_label = -1\n",
    "    if 'event_label' in df_final_filtered.columns:\n",
    "         try:\n",
    "             unique_labels = df_final_filtered['event_label'].unique()\n",
    "             if len(unique_labels) == 1: event_label = int(unique_labels[0]); print(f\"Label '{event_label}' from 'event_label' column.\")\n",
    "             else: event_label = int(df_final_filtered['event_label'].iloc[0]); print(f\"Warning: Multiple labels. Using label from first row: {event_label}.\")\n",
    "         except: event_label = -1\n",
    "    elif \"background\" in input_filepath.lower(): event_label = 0; print(\"Label '0' from filename.\")\n",
    "    elif \"ppbba\" in input_filepath.lower(): event_label = 0; print(\"Label '0' from filename.\")\n",
    "    elif \"ax\" in input_filepath.lower() or \"sig\" in input_filepath.lower(): event_label = 1; print(\"Label '1' from filename.\")\n",
    "    if event_label == -1: print(\"Warning: Event label undetermined. Using -1.\")\n",
    "\n",
    "    # 4. Process Events using the combined function\n",
    "    combined_data_list = []\n",
    "    print(f\"\\nConverting {len(df_final_filtered)} filtered events to combined GNN/LorentzNet format...\")\n",
    "    for event_tuple in tqdm(df_final_filtered.itertuples(index=False, name=None), total=len(df_final_filtered), desc=\"Processing Events\"):\n",
    "        event_series = pd.Series(event_tuple, index=df_final_filtered.columns)\n",
    "        combined_dict = process_event_combined(event_series, event_label, max_jets_input_df, max_photons_input_df)\n",
    "        # Your previous filtering on the gnn_dict\n",
    "        if (combined_dict is not None) and \\\n",
    "           (combined_dict.get('num_nodes', 0) >= 3) and \\\n",
    "           (combined_dict.get('num_btag_jets', 0) >= 2) and \\\n",
    "           (combined_dict.get('num_isophotons', 0) >= 1):\n",
    "            combined_data_list.append(combined_dict)\n",
    "\n",
    "    print(f\"\\nSuccessfully prepared {len(combined_data_list)} events for combined format out of {len(df_final_filtered)} filtered events.\")\n",
    "\n",
    "    # 5. Save Results\n",
    "    if combined_data_list:\n",
    "        success = save_to_json(combined_data_list, output_filepath)\n",
    "        if success:\n",
    "            print(f\"\\nPipeline finished successfully. Combined data saved to {output_filepath}\")\n",
    "            try:\n",
    "                with open(output_filepath, 'r') as f: sample_data = json.load(f)\n",
    "                if sample_data: print(\"\\n--- Sample Combined Event:\\n\");pprint(sample_data[0])\n",
    "            except: pass\n",
    "        else: print(\"\\nPipeline finished, but saving the JSON file failed.\")\n",
    "    else: print(\"\\nPipeline finished, but no events were successfully prepared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dad060a8-dba2-463c-8fea-8e55a39fb5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 files to preprocess and convert to JSON file: \n",
      "['./raw_txt_data/ppbba_500k_minpt10_15jets_etafiltered_corrected.txt', './raw_txt_data/ppbba_500k_minpt20_15jets_etafiltered_corrected.txt', './raw_txt_data/ppzaxbba_ax15_200k_minpt10_15jets_etafiltered_corrected.txt', './raw_txt_data/ppzaxbba_ax15_200k_minpt20_15jets_etafiltered_corrected.txt', './raw_txt_data/ppzaxbba_ax45_200k_minpt10_15jets_etafiltered_corrected.txt', './raw_txt_data/ppzaxbba_ax45_200k_minpt20_15jets_etafiltered_corrected.txt']\n",
      "\n",
      "Files will be saved to paths: \n",
      "['./onlyAny2bj_onlyAny1p/ppbba_500k_minpt10_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json', './onlyAny2bj_onlyAny1p/ppbba_500k_minpt20_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json', './onlyAny2bj_onlyAny1p/ppzaxbba_ax15_200k_minpt10_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json', './onlyAny2bj_onlyAny1p/ppzaxbba_ax15_200k_minpt20_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json', './onlyAny2bj_onlyAny1p/ppzaxbba_ax45_200k_minpt10_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json', './onlyAny2bj_onlyAny1p/ppzaxbba_ax45_200k_minpt20_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json']\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "\n",
      "Starting to process the files...\n",
      "Loading data from ./raw_txt_data/ppbba_500k_minpt10_15jets_etafiltered_corrected.txt...\n",
      "--- Data loaded successfully: 500000 events, 129 columns :)\n",
      "Applying Eta filter: Keeping jets with Eta between -2.5 and 2.5.\n",
      "--- Eta filtering complete :)\n",
      "['jet1_Eta', 'jet2_Eta', 'jet3_Eta', 'jet4_Eta', 'jet5_Eta', 'jet6_Eta', 'jet7_Eta', 'jet8_Eta', 'jet9_Eta', 'jet10_Eta', 'jet11_Eta', 'jet12_Eta', 'jet13_Eta', 'jet14_Eta', 'jet15_Eta']\n",
      "Removed 29152 events with no valid jets AND no valid photons :)\n",
      "Number of events after empty event filtering: 470848\n",
      "Label '0' from filename.\n",
      "\n",
      "Converting 470848 filtered events to combined GNN/LorentzNet format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Events: 100%|██████████| 470848/470848 [02:24<00:00, 3259.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully prepared 5931 events for combined format out of 470848 filtered events.\n",
      "Attempting to save 5931 events to JSON file: ./onlyAny2bj_onlyAny1p/ppbba_500k_minpt10_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "JSON file saved successfully.\n",
      "\n",
      "Pipeline finished successfully. Combined data saved to ./onlyAny2bj_onlyAny1p/ppbba_500k_minpt10_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "{'edge_index': [[0, 1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 3],\n",
      "                [1, 0, 2, 0, 3, 0, 2, 1, 3, 1, 3, 2]],\n",
      " 'edges': [1.0952445377964684,\n",
      "           1.0952445377964684,\n",
      "           3.6744774117619774,\n",
      "           3.6744774117619774,\n",
      "           2.119689668842116,\n",
      "           2.119689668842116,\n",
      "           3.2793359684841685,\n",
      "           3.2793359684841685,\n",
      "           1.0313693498281786,\n",
      "           1.0313693498281786,\n",
      "           3.052316685345903,\n",
      "           3.052316685345903],\n",
      " 'event_label': 0,\n",
      " 'eventno': 262,\n",
      " 'h_scalars': [[0.0, 0.0, 0.053012993692885355],\n",
      "               [1.0, 1.0, 0.04139574253257708],\n",
      "               [1.0, 0.0, 0.06922597489223113],\n",
      "               [1.0, 1.0, 0.0]],\n",
      " 'invMass_2leadingbj': 23.727759805112264,\n",
      " 'invMass_2leadingbj1p': 79.35857459702514,\n",
      " 'jet_btag_label': [None, 1.0, 0.0, 1.0],\n",
      " 'leading_isophoton_pT': 45.2844,\n",
      " 'node_labels': [0, 1, 1, 1],\n",
      " 'nodes': [[0.55687, -0.181863, 45.2844, 52.4892],\n",
      "           [-0.460313, 0.224215, 38.8455, 43.0342],\n",
      "           [-2.304, -2.48777, 13.1734, 66.618],\n",
      "           [-1.4672, 0.447601, 12.5798, 28.73]],\n",
      " 'num_btag_jets': 2,\n",
      " 'num_isophotons': 1,\n",
      " 'num_nodes': 4,\n",
      " 'x_coords': [[52.4892, 44.5376, -8.19025, 26.5412],\n",
      "              [43.0342, 37.8732, 8.63695, -18.5193],\n",
      "              [66.618, -10.4565, -8.01238, -65.3025],\n",
      "              [28.73, 11.3405, 5.44458, -25.8295]]}\n",
      "\n",
      "--- Sample Combined Event:\n",
      " None\n",
      ".\n",
      ".\n",
      ".\n",
      "Loading data from ./raw_txt_data/ppbba_500k_minpt20_15jets_etafiltered_corrected.txt...\n",
      "--- Data loaded successfully: 500000 events, 129 columns :)\n",
      "Applying Eta filter: Keeping jets with Eta between -2.5 and 2.5.\n",
      "--- Eta filtering complete :)\n",
      "['jet1_Eta', 'jet2_Eta', 'jet3_Eta', 'jet4_Eta', 'jet5_Eta', 'jet6_Eta', 'jet7_Eta', 'jet8_Eta', 'jet9_Eta', 'jet10_Eta', 'jet11_Eta', 'jet12_Eta', 'jet13_Eta', 'jet14_Eta', 'jet15_Eta']\n",
      "Removed 144409 events with no valid jets AND no valid photons :)\n",
      "Number of events after empty event filtering: 355591\n",
      "Label '0' from filename.\n",
      "\n",
      "Converting 355591 filtered events to combined GNN/LorentzNet format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Events: 100%|██████████| 355591/355591 [01:27<00:00, 4079.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully prepared 1939 events for combined format out of 355591 filtered events.\n",
      "Attempting to save 1939 events to JSON file: ./onlyAny2bj_onlyAny1p/ppbba_500k_minpt20_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "JSON file saved successfully.\n",
      "\n",
      "Pipeline finished successfully. Combined data saved to ./onlyAny2bj_onlyAny1p/ppbba_500k_minpt20_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "{'edge_index': [[0, 1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 3],\n",
      "                [1, 0, 2, 0, 3, 0, 2, 1, 3, 1, 3, 2]],\n",
      " 'edges': [1.5214262041602122,\n",
      "           1.5214262041602122,\n",
      "           2.041574429594601,\n",
      "           2.041574429594601,\n",
      "           1.257692013262786,\n",
      "           1.257692013262786,\n",
      "           0.5410989753841342,\n",
      "           0.5410989753841342,\n",
      "           1.801105101150224,\n",
      "           1.801105101150224,\n",
      "           2.1094013598617325,\n",
      "           2.1094013598617325],\n",
      " 'event_label': 0,\n",
      " 'eventno': 541,\n",
      " 'h_scalars': [[0.0, 0.0, 0.0],\n",
      "               [1.0, 1.0, 0.07843825672851006],\n",
      "               [1.0, 1.0, 0.0],\n",
      "               [1.0, 0.0, 0.0]],\n",
      " 'invMass_2leadingbj': 17.72467157317614,\n",
      " 'invMass_2leadingbj1p': 61.96753972827096,\n",
      " 'jet_btag_label': [None, 1.0, 1.0, 0.0],\n",
      " 'leading_isophoton_pT': 20.8574,\n",
      " 'node_labels': [0, 1, 1, 1],\n",
      " 'nodes': [[-0.448283, 2.25532, 20.8574, 22.9884],\n",
      "           [-0.0075974, -2.57166, 34.8986, 34.8996],\n",
      "           [0.306125, -2.13079, 30.9913, 32.4548],\n",
      "           [0.799982, 2.10162, 22.9505, 30.6944]],\n",
      " 'num_btag_jets': 2,\n",
      " 'num_isophotons': 1,\n",
      " 'num_nodes': 4,\n",
      " 'x_coords': [[22.9884, -13.1882, 16.1587, -9.66631],\n",
      "              [34.8996, -29.3824, -18.8303, -0.265141],\n",
      "              [32.4548, -16.4621, -26.2576, 9.63607],\n",
      "              [30.6944, -11.6185, 19.7923, 20.3819]]}\n",
      "\n",
      "--- Sample Combined Event:\n",
      " None\n",
      ".\n",
      ".\n",
      ".\n",
      "Loading data from ./raw_txt_data/ppzaxbba_ax15_200k_minpt10_15jets_etafiltered_corrected.txt...\n",
      "--- Data loaded successfully: 200000 events, 129 columns :)\n",
      "Applying Eta filter: Keeping jets with Eta between -2.5 and 2.5.\n",
      "--- Eta filtering complete :)\n",
      "['jet1_Eta', 'jet2_Eta', 'jet3_Eta', 'jet4_Eta', 'jet5_Eta', 'jet6_Eta', 'jet7_Eta', 'jet8_Eta', 'jet9_Eta', 'jet10_Eta', 'jet11_Eta', 'jet12_Eta', 'jet13_Eta', 'jet14_Eta', 'jet15_Eta']\n",
      "Removed 24704 events with no valid jets AND no valid photons :)\n",
      "Number of events after empty event filtering: 175296\n",
      "Label '1' from filename.\n",
      "\n",
      "Converting 175296 filtered events to combined GNN/LorentzNet format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Events: 100%|██████████| 175296/175296 [01:02<00:00, 2808.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully prepared 3488 events for combined format out of 175296 filtered events.\n",
      "Attempting to save 3488 events to JSON file: ./onlyAny2bj_onlyAny1p/ppzaxbba_ax15_200k_minpt10_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "JSON file saved successfully.\n",
      "\n",
      "Pipeline finished successfully. Combined data saved to ./onlyAny2bj_onlyAny1p/ppzaxbba_ax15_200k_minpt10_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "{'edge_index': [[0, 1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 3],\n",
      "                [1, 0, 2, 0, 3, 0, 2, 1, 3, 1, 3, 2]],\n",
      " 'edges': [2.8989862509236968,\n",
      "           2.8989862509236968,\n",
      "           3.004379511988102,\n",
      "           3.004379511988102,\n",
      "           3.0607649100713368,\n",
      "           3.0607649100713368,\n",
      "           0.5335701639184861,\n",
      "           0.5335701639184861,\n",
      "           2.2034447201824694,\n",
      "           2.2034447201824694,\n",
      "           2.0566762871789037,\n",
      "           2.0566762871789037],\n",
      " 'event_label': 1,\n",
      " 'eventno': 30,\n",
      " 'h_scalars': [[0.0, 0.0, 0.04174796282713779],\n",
      "               [1.0, 1.0, 0.0],\n",
      "               [1.0, 1.0, 0.0],\n",
      "               [1.0, 0.0, 0.0]],\n",
      " 'invMass_2leadingbj': 9.266433828415266,\n",
      " 'invMass_2leadingbj1p': 85.85608864441471,\n",
      " 'jet_btag_label': [None, 1.0, 1.0, 0.0],\n",
      " 'leading_isophoton_pT': 31.3375,\n",
      " 'node_labels': [0, 1, 1, 1],\n",
      " 'nodes': [[-0.146968, 3.11968, 31.3375, 31.6766],\n",
      "           [1.5536, -0.8157, 21.4545, 52.9918],\n",
      "           [1.1582, -0.457432, 14.0265, 24.5342],\n",
      "           [2.28595, 1.26248, 12.8745, 63.9654]],\n",
      " 'num_btag_jets': 2,\n",
      " 'num_isophotons': 1,\n",
      " 'num_nodes': 4,\n",
      " 'x_coords': [[31.6766, -31.33, 0.68674, -4.6222],\n",
      "              [52.9918, 14.704, -15.6233, 48.4545],\n",
      "              [24.5342, 12.5845, -6.19476, 20.1292],\n",
      "              [63.9654, 3.90687, 12.2674, 62.6564]]}\n",
      "\n",
      "--- Sample Combined Event:\n",
      " None\n",
      ".\n",
      ".\n",
      ".\n",
      "Loading data from ./raw_txt_data/ppzaxbba_ax15_200k_minpt20_15jets_etafiltered_corrected.txt...\n",
      "--- Data loaded successfully: 200000 events, 129 columns :)\n",
      "Applying Eta filter: Keeping jets with Eta between -2.5 and 2.5.\n",
      "--- Eta filtering complete :)\n",
      "['jet1_Eta', 'jet2_Eta', 'jet3_Eta', 'jet4_Eta', 'jet5_Eta', 'jet6_Eta', 'jet7_Eta', 'jet8_Eta', 'jet9_Eta', 'jet10_Eta', 'jet11_Eta', 'jet12_Eta', 'jet13_Eta', 'jet14_Eta', 'jet15_Eta']\n",
      "Removed 50400 events with no valid jets AND no valid photons :)\n",
      "Number of events after empty event filtering: 149600\n",
      "Label '1' from filename.\n",
      "\n",
      "Converting 149600 filtered events to combined GNN/LorentzNet format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Events: 100%|██████████| 149600/149600 [00:43<00:00, 3450.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully prepared 570 events for combined format out of 149600 filtered events.\n",
      "Attempting to save 570 events to JSON file: ./onlyAny2bj_onlyAny1p/ppzaxbba_ax15_200k_minpt20_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "JSON file saved successfully.\n",
      "\n",
      "Pipeline finished successfully. Combined data saved to ./onlyAny2bj_onlyAny1p/ppzaxbba_ax15_200k_minpt20_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "{'edge_index': [[0, 1, 0, 2, 1, 2], [1, 0, 2, 0, 2, 1]],\n",
      " 'edges': [2.9923461582176616,\n",
      "           2.9923461582176616,\n",
      "           2.866177727299879,\n",
      "           2.866177727299879,\n",
      "           0.5579355171522961,\n",
      "           0.5579355171522961],\n",
      " 'event_label': 1,\n",
      " 'eventno': 292,\n",
      " 'h_scalars': [[0.0, 0.0, 0.0],\n",
      "               [1.0, 1.0, 0.0],\n",
      "               [1.0, 1.0, 0.053466306223098614]],\n",
      " 'invMass_2leadingbj': 13.256282227680105,\n",
      " 'invMass_2leadingbj1p': 95.62838682036785,\n",
      " 'jet_btag_label': [None, 1.0, 1.0],\n",
      " 'leading_isophoton_pT': 43.9066,\n",
      " 'node_labels': [0, 1, 1],\n",
      " 'nodes': [[1.30089, -1.86821, 43.9066, 86.6024],\n",
      "           [1.77274, 1.0867, 25.8272, 78.2158],\n",
      "           [1.93631, 1.62012, 22.335, 79.0364]],\n",
      " 'num_btag_jets': 2,\n",
      " 'num_isophotons': 1,\n",
      " 'num_nodes': 3,\n",
      " 'x_coords': [[86.6024, -12.8667, -41.979, 74.6471],\n",
      "              [78.2158, 12.0202, 22.8596, 73.8287],\n",
      "              [79.0364, -1.10121, 22.3078, 75.8149]]}\n",
      "\n",
      "--- Sample Combined Event:\n",
      " None\n",
      ".\n",
      ".\n",
      ".\n",
      "Loading data from ./raw_txt_data/ppzaxbba_ax45_200k_minpt10_15jets_etafiltered_corrected.txt...\n",
      "--- Data loaded successfully: 200000 events, 129 columns :)\n",
      "Applying Eta filter: Keeping jets with Eta between -2.5 and 2.5.\n",
      "--- Eta filtering complete :)\n",
      "['jet1_Eta', 'jet2_Eta', 'jet3_Eta', 'jet4_Eta', 'jet5_Eta', 'jet6_Eta', 'jet7_Eta', 'jet8_Eta', 'jet9_Eta', 'jet10_Eta', 'jet11_Eta', 'jet12_Eta', 'jet13_Eta', 'jet14_Eta', 'jet15_Eta']\n",
      "Removed 23309 events with no valid jets AND no valid photons :)\n",
      "Number of events after empty event filtering: 176691\n",
      "Label '1' from filename.\n",
      "\n",
      "Converting 176691 filtered events to combined GNN/LorentzNet format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Events: 100%|██████████| 176691/176691 [01:06<00:00, 2675.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully prepared 6773 events for combined format out of 176691 filtered events.\n",
      "Attempting to save 6773 events to JSON file: ./onlyAny2bj_onlyAny1p/ppzaxbba_ax45_200k_minpt10_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "JSON file saved successfully.\n",
      "\n",
      "Pipeline finished successfully. Combined data saved to ./onlyAny2bj_onlyAny1p/ppzaxbba_ax45_200k_minpt10_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "{'edge_index': [[0, 1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 3],\n",
      "                [1, 0, 2, 0, 3, 0, 2, 1, 3, 1, 3, 2]],\n",
      " 'edges': [2.2661411295230494,\n",
      "           2.2661411295230494,\n",
      "           3.027992839451096,\n",
      "           3.027992839451096,\n",
      "           4.3909377077909,\n",
      "           4.3909377077909,\n",
      "           2.032559334518183,\n",
      "           2.032559334518183,\n",
      "           3.5570066467601658,\n",
      "           3.5570066467601658,\n",
      "           3.881371923315389,\n",
      "           3.881371923315389],\n",
      " 'event_label': 1,\n",
      " 'eventno': 66,\n",
      " 'h_scalars': [[0.0, 0.0, 0.0],\n",
      "               [1.0, 1.0, 0.10602877722220876],\n",
      "               [1.0, 1.0, 0.014743133994001522],\n",
      "               [1.0, 0.0, 0.0]],\n",
      " 'invMass_2leadingbj': 43.876691043395695,\n",
      " 'invMass_2leadingbj1p': 99.95583695260417,\n",
      " 'jet_btag_label': [None, 1.0, 1.0, 0.0],\n",
      " 'leading_isophoton_pT': 29.9921,\n",
      " 'node_labels': [0, 1, 1, 1],\n",
      " 'nodes': [[2.42779, -2.17497, 29.9921, 171.285],\n",
      "           [1.48071, -0.116224, 30.1322, 69.6591],\n",
      "           [0.582781, 1.70724, 19.004, 22.3236],\n",
      "           [-1.87452, -1.29721, 16.5989, 55.3667]],\n",
      " 'num_btag_jets': 2,\n",
      " 'num_isophotons': 1,\n",
      " 'num_nodes': 4,\n",
      " 'x_coords': [[171.285, -17.0379, -24.6828, 168.639],\n",
      "              [69.6591, 29.9289, -3.49422, 62.8047],\n",
      "              [22.3236, -2.585, 18.8274, 11.7128],\n",
      "              [55.3667, 4.48473, -15.9816, -52.82]]}\n",
      "\n",
      "--- Sample Combined Event:\n",
      " None\n",
      ".\n",
      ".\n",
      ".\n",
      "Loading data from ./raw_txt_data/ppzaxbba_ax45_200k_minpt20_15jets_etafiltered_corrected.txt...\n",
      "--- Data loaded successfully: 200000 events, 129 columns :)\n",
      "Applying Eta filter: Keeping jets with Eta between -2.5 and 2.5.\n",
      "--- Eta filtering complete :)\n",
      "['jet1_Eta', 'jet2_Eta', 'jet3_Eta', 'jet4_Eta', 'jet5_Eta', 'jet6_Eta', 'jet7_Eta', 'jet8_Eta', 'jet9_Eta', 'jet10_Eta', 'jet11_Eta', 'jet12_Eta', 'jet13_Eta', 'jet14_Eta', 'jet15_Eta']\n",
      "Removed 51477 events with no valid jets AND no valid photons :)\n",
      "Number of events after empty event filtering: 148523\n",
      "Label '1' from filename.\n",
      "\n",
      "Converting 148523 filtered events to combined GNN/LorentzNet format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Events: 100%|██████████| 148523/148523 [00:42<00:00, 3457.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully prepared 1658 events for combined format out of 148523 filtered events.\n",
      "Attempting to save 1658 events to JSON file: ./onlyAny2bj_onlyAny1p/ppzaxbba_ax45_200k_minpt20_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "JSON file saved successfully.\n",
      "\n",
      "Pipeline finished successfully. Combined data saved to ./onlyAny2bj_onlyAny1p/ppzaxbba_ax45_200k_minpt20_15jets_etafiltered_corrected_onlyAny2bj_onlyAny1p_LorentzNet_data.json\n",
      "{'edge_index': [[0, 1, 0, 2, 0, 3, 0, 4, 1, 2, 1, 3, 1, 4, 2, 3, 2, 4, 3, 4],\n",
      "                [1, 0, 2, 0, 3, 0, 4, 0, 2, 1, 3, 1, 4, 1, 3, 2, 4, 2, 4, 3]],\n",
      " 'edges': [2.8568541454335303,\n",
      "           2.8568541454335303,\n",
      "           2.9492141862111336,\n",
      "           2.9492141862111336,\n",
      "           0.7218868799583492,\n",
      "           0.7218868799583492,\n",
      "           1.082784586113508,\n",
      "           1.082784586113508,\n",
      "           1.1807386463777665,\n",
      "           1.1807386463777665,\n",
      "           3.080221988592543,\n",
      "           3.080221988592543,\n",
      "           1.8103871319041125,\n",
      "           1.8103871319041125,\n",
      "           2.287163600669834,\n",
      "           2.287163600669834,\n",
      "           2.9182433524389806,\n",
      "           2.9182433524389806,\n",
      "           1.423474293417693,\n",
      "           1.423474293417693],\n",
      " 'event_label': 1,\n",
      " 'eventno': 107,\n",
      " 'h_scalars': [[0.0, 0.0, 0.48338572588978335],\n",
      "               [1.0, 1.0, 0.0],\n",
      "               [1.0, 0.0, 0.0],\n",
      "               [1.0, 1.0, 0.06453659117433364],\n",
      "               [1.0, 1.0, 0.03608393548065773]],\n",
      " 'invMass_2leadingbj': 126.9067421513987,\n",
      " 'invMass_2leadingbj1p': 293.6885872730392,\n",
      " 'jet_btag_label': [None, 1.0, 0.0, 1.0, 1.0],\n",
      " 'leading_isophoton_pT': 132.494,\n",
      " 'node_labels': [0, 1, 1, 1, 1],\n",
      " 'nodes': [[-1.0965, -2.11916, 132.494, 220.451],\n",
      "           [-0.315563, 1.41598, 113.861, 119.578],\n",
      "           [0.358182, 0.446335, 61.9298, 65.9451],\n",
      "           [-0.542916, -1.65584, 34.9505, 40.2293],\n",
      "           [-0.594205, -3.07839, 34.6261, 40.921]],\n",
      " 'num_btag_jets': 3,\n",
      " 'num_isophotons': 1,\n",
      " 'num_nodes': 5,\n",
      " 'x_coords': [[220.451, -69.0682, -113.068, -176.192],\n",
      "              [119.578, 17.557, 112.5, -36.5297],\n",
      "              [65.9451, 55.8629, 26.7328, 22.6595],\n",
      "              [40.2293, -2.96872, -34.8242, -19.9212],\n",
      "              [40.921, -34.557, -2.18686, -21.8073]]}\n",
      "\n",
      "--- Sample Combined Event:\n",
      " None\n",
      ".\n",
      ".\n",
      ".\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "All files processed SUCCESSFULLY :)\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_SEPARATOR = '\\t'\n",
    "    ETA_MIN_FILTER = -2.5\n",
    "    ETA_MAX_FILTER = 2.5\n",
    "\n",
    "    # Ensure global constants are defined\n",
    "    JET_DF_FEATURES = ['Eta', 'Phi', 'pT', 'Px', 'Py', 'Pz', 'E']\n",
    "    LORENTZNET_SCALAR_FEATURE_ORDER = ['particle_type', 'btag_status', 'invariant_mass']\n",
    "    MAX_JETS_INPUT = 15\n",
    "    MAX_PHOTONS_INPUT = 1\n",
    "    FOUR_VECTOR_COLS_FROM_DF = ['E', 'Px', 'Py', 'Pz']\n",
    "    SCALAR_JET_FEATURES_FROM_DF = ['btag']\n",
    "    SCALAR_PHOTON_FEATURES_FROM_DF = []\n",
    "    BASE_TXT_DATA_DIR = \"./raw_txt_data\"\n",
    "    INPUT_FILE_PATHS = []\n",
    "    for files in os.listdir(BASE_TXT_DATA_DIR):\n",
    "        if files.endswith(\".txt\"):\n",
    "            INPUT_FILE_PATHS.append(os.path.join(BASE_TXT_DATA_DIR, files))\n",
    "    \n",
    "    print(f\"Found {len(INPUT_FILE_PATHS)} files to preprocess and convert to JSON file: \\n{INPUT_FILE_PATHS}\")\n",
    "    \n",
    "    GNN_OUTPUT_JSON_FILE_PATHS = []\n",
    "    BASE_OUTPUT_DIR = \"./onlyAny2bj_onlyAny1p\"\n",
    "    # BASE_OUTPUT_DIR = \"./\"\n",
    "    os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "    for paths in INPUT_FILE_PATHS:\n",
    "        if paths.endswith(\".txt\"):\n",
    "            output_path = paths.split(\"/\")[-1][:-4] + '_onlyAny2bj_onlyAny1p_LorentzNet_data.json'\n",
    "            GNN_OUTPUT_JSON_FILE_PATHS.append(os.path.join(BASE_OUTPUT_DIR, output_path))\n",
    "    \n",
    "    print(f\"\\nFiles will be saved to paths: \\n{GNN_OUTPUT_JSON_FILE_PATHS}\")\n",
    "    for _ in range(5):\n",
    "        print(\"*\")\n",
    "    print(f\"\\nStarting to process the files...\")\n",
    "    for input_file, output_file in zip(INPUT_FILE_PATHS, GNN_OUTPUT_JSON_FILE_PATHS):\n",
    "        main_combined_pipeline(\n",
    "        input_filepath=input_file,\n",
    "        output_filepath=output_file,\n",
    "        max_jets_input_df=MAX_JETS_INPUT,\n",
    "        max_photons_input_df=MAX_PHOTONS_INPUT,\n",
    "        eta_min_filter=ETA_MIN_FILTER,\n",
    "        eta_max_filter=ETA_MAX_FILTER,\n",
    "        sep=INPUT_FILE_SEPARATOR\n",
    "        )\n",
    "        for _ in range(3):\n",
    "            print(\".\")\n",
    "    for _ in range(5):\n",
    "        print(\"*\")\n",
    "    print(f\"All files processed SUCCESSFULLY :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1543c58b-a446-44af-939d-10b229c7c1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
